# Report

A gradient boosted decision tree was implemented using HistGradientBoostingClassifier from the scikit-learn library. This is the library's equivalence to the popular XGBoost algorithm. I decided to stick with the scikit-learn package for this assignment to further explore its machine learning offerings. The purpose of the model originally was to to build an NBA championship predictor from game data over the span of a year. So I first attempted to build a model which would simply determine a single game's winner. To build the model a temporal 80-20% test train split was done, providing ample data for the model to learn from and then be evaluated on. The model was trained to classify a game winner based on the game's retrospective data.

However, as  I started building I realized there was a bit of division between what I had and what I wanted. Intitially I wanted to build an NBA predictor, which would determine a games outcome based on team statistics, but upon sitting down and trying to do the actual implementation I realized an effective implementation for that problem type is rather hard. I only had hindsight data for the game I was trying to evaluate, and so the most straightforward approach of training it on the games and withholding the classification labels at first seemed like the proper approach; but this introduced a number of issues.

First, it is a form of temporal leakage, as a predictor of who would win prior to a game's start would not have any box scores for said game. If I were to do something like that it would have to be trained on and fed a sort of sliding window slice of data, where you perhaps compute the previous 10 games statistics weighted, and then the previous 30 games statistics and results weighted a bit less, etc. to give the model a notion of how the two teams are doing as the approach the faceoff. Secondly, the games have a lot more unknowns and variables when predicting completely beforehand. For one, you have to account for injuries and missing players. Basketball perhaps more than any other team sport is most influenced by the performance of single individual players. If you have your second best or even fifth best player sit, it can effect the outcome greatly, and the model has no individual data to even account for that, never mind the implemenetation being a more difficult one too.

However, this model trained on only one side of the post-game data, without knowledge of the winner or statistical differences between the two teams, performed rather well in classifying winners simply from that. It is important to withhold the other teams stats from the model, because it otherwise can then simply infer the difference between, say their points, and then the answer is embedded in the data and you have another form of leakage. But with just one of the team's statistics, it performed with about 80% accuracy. It should be noted that baseline predictors like the hometeam team win about 50-60% of the time, so 80% in context is only about 20% better than baseline, but it is still a significant classification result. The confusion matrix for the model was symmetrical with reasonable values, evidence in support of there being minimal bias regarding favoring to classify as a "win" or a "loss" more often.

<p align="center">
  <img src="../images/Confusion matrix on original model run.png" height="385">
</p>

This realization in the hurdles towards making a classical "predictive model" led me to rethinking how I might use this in a different context. My thought process is that I can perhaps use this model to gain insights into certain things which do predict success, so even if this model doesnt outright predict winners beforehand, it's insights could be used in another implementation in support of doing so. Decision trees are known to have good interpretability, and in XGBoost you can derive decision logic directly from a trained tree. This would be an interesting area to explore, continuing down a similar model pipeline but for different purposes.
