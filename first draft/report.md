# Report

A gradient boosted decision tree was implemented using HistGradientBoostingClassifier from the scikit-learn library. This is the library's equivalence to the popular XGBoost algorithm. I decided to stick with the scikit-learn package for this assignment to further explore it. The purpose of the model originally was to to build an NBA champion predictor from game data over the year. So I first attempted to build a model which would simply determine a game's winner. To build the model a temporal 80-20% test train split was done, providing ample data for the model to learn from and then be evaluated on. The model was trained to classify a game winner based on the game's retrospective data.

However, as  I started building I realized there was a bit of division between what I had and what I wanted. Intitially I wanted to build an NBA predictor, which would determine a games outcome based on team statistics, but upon sitting down and trying to do the actual implementation I realized an effective implementation for that problem type is rather hard. I only had data which had of course already occurred, and so the most straightforward approach of training it on the game data without the label of winner or loser at first seemed like a plausible approach. But this introduces issues for a number of reasons.

First, it is a form of temporal leakage, as a predictor of who would win prior to a game starting would not have any box scores for said game. If I were to do something like that it would have to be trained on and fed a sort of sliding window slice of data, where you perhaps compute the previous 10 games weighted, and then the previous 30 games statistics and results weighted a bit less, etc. to give the model a notion of how the two teams are doing as the approach the faceoff. Secondly, the games have a lot more unknowns and variables when predicting completely beforehand. For one, you have to account for injuries and missing players. Basketball perhaps more than any other team sport is most influenced by the performance of an individual player. Have your second best or fifth best player sit and it can effect the outcome greatly, and the model has no individual data to even account for that, let alone the implemenetation being discernably more difficult.

However, the model trained on only one side of the post game data, without knowledge knowledge of the winner or statistical differences between the two teams, performed rather well in classifying winners simply from this. It's important to withhold the other teams stats from the model, because it can then simply infer the difference between, say points, and then the answer is embedded in the data and you have another form of leakage! But with just one team's statistics, it performed with about 80% accuracy. It should be noted that baseline predictors like the hometeam win about 50-60% of the time, so 80% in context is only about 20% better than baseline but is still a significant classification result. The confusion matrix for the model showed as symmetrical with reasonable values, supporting minimal bias regarding favoring classifying a "win" or a "loss" more.

<p align="center">
<img height="400" alt="Confusion matrix on original model run" src="https://github.com/user-attachments/assets/a80cb53c-b0f4-4640-8344-2b6bc6f19a7e" />
</p>

This realization in the hurdles towards making a classical "predictive model" led me to rethinking how I might use this in a different context. My thought process is that I can perhaps use this model to gain insights into certain things which do predict success, so even if this model doesnt predict outright winners beforehand, it's insights could be used in another implementation to support doing so. Decision trees are known to have good interpretability, and in XGBoost you can derive decision logic directly from a trained tree. This would be an interesting area to explore, continuing down a similar model pipeline but for different purposes.
